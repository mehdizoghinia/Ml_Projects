{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Research Final 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLXKSYUJRlsg"
      },
      "source": [
        "# import libaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHDDLYqzQN8M"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import random as rnd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgkP54YYReiq"
      },
      "source": [
        "# Import algs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P70EUg_yRBdL"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC,LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d01x_wcORxfz",
        "outputId": "f2bc092c-644a-47fd-b18e-bbcca4a77625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCNzqLIhR20h",
        "outputId": "b1bca5b7-99a6-47b9-835d-b10ebf5e0ee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im50MHm2RuUb"
      },
      "source": [
        "data = pd.read_csv(\"HCV-Egy-Data.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVcTNngXSNLD",
        "outputId": "c86e76a9-b8cf-4362-c8ea-a06eb47a14d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "data.head(5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Fever</th>\n",
              "      <th>Nausea/Vomting</th>\n",
              "      <th>Headache</th>\n",
              "      <th>Diarrhea</th>\n",
              "      <th>Fatigue &amp; generalized bone ache</th>\n",
              "      <th>Jaundice</th>\n",
              "      <th>Epigastric pain</th>\n",
              "      <th>WBC</th>\n",
              "      <th>RBC</th>\n",
              "      <th>HGB</th>\n",
              "      <th>Plat</th>\n",
              "      <th>AST 1</th>\n",
              "      <th>ALT 1</th>\n",
              "      <th>ALT4</th>\n",
              "      <th>ALT 12</th>\n",
              "      <th>ALT 24</th>\n",
              "      <th>ALT 36</th>\n",
              "      <th>ALT 48</th>\n",
              "      <th>ALT after 24 w</th>\n",
              "      <th>RNA Base</th>\n",
              "      <th>RNA 4</th>\n",
              "      <th>RNA 12</th>\n",
              "      <th>RNA EOT</th>\n",
              "      <th>RNA EF</th>\n",
              "      <th>Baseline histological Grading</th>\n",
              "      <th>Baselinehistological staging</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7425</td>\n",
              "      <td>4248807.0</td>\n",
              "      <td>14</td>\n",
              "      <td>112132.0</td>\n",
              "      <td>99</td>\n",
              "      <td>84</td>\n",
              "      <td>52.0</td>\n",
              "      <td>109</td>\n",
              "      <td>81</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>655330</td>\n",
              "      <td>634536</td>\n",
              "      <td>288194</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>12101</td>\n",
              "      <td>4429425.0</td>\n",
              "      <td>10</td>\n",
              "      <td>129367.0</td>\n",
              "      <td>91</td>\n",
              "      <td>123</td>\n",
              "      <td>95.0</td>\n",
              "      <td>75</td>\n",
              "      <td>113</td>\n",
              "      <td>57</td>\n",
              "      <td>123</td>\n",
              "      <td>44</td>\n",
              "      <td>40620</td>\n",
              "      <td>538635</td>\n",
              "      <td>637056</td>\n",
              "      <td>336804</td>\n",
              "      <td>31085</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4178</td>\n",
              "      <td>4621191.0</td>\n",
              "      <td>12</td>\n",
              "      <td>151522.0</td>\n",
              "      <td>113</td>\n",
              "      <td>49</td>\n",
              "      <td>95.0</td>\n",
              "      <td>107</td>\n",
              "      <td>116</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>571148</td>\n",
              "      <td>661346</td>\n",
              "      <td>5</td>\n",
              "      <td>735945</td>\n",
              "      <td>558829</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6490</td>\n",
              "      <td>4794631.0</td>\n",
              "      <td>10</td>\n",
              "      <td>146457.0</td>\n",
              "      <td>43</td>\n",
              "      <td>64</td>\n",
              "      <td>109.0</td>\n",
              "      <td>80</td>\n",
              "      <td>88</td>\n",
              "      <td>48</td>\n",
              "      <td>77</td>\n",
              "      <td>33</td>\n",
              "      <td>1041941</td>\n",
              "      <td>449939</td>\n",
              "      <td>585688</td>\n",
              "      <td>744463</td>\n",
              "      <td>582301</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3661</td>\n",
              "      <td>4606375.0</td>\n",
              "      <td>11</td>\n",
              "      <td>187684.0</td>\n",
              "      <td>99</td>\n",
              "      <td>104</td>\n",
              "      <td>67.0</td>\n",
              "      <td>48</td>\n",
              "      <td>120</td>\n",
              "      <td>94</td>\n",
              "      <td>90</td>\n",
              "      <td>30</td>\n",
              "      <td>660410</td>\n",
              "      <td>738756</td>\n",
              "      <td>3731527</td>\n",
              "      <td>338946</td>\n",
              "      <td>242861</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age   Gender  ...  Baseline histological Grading  Baselinehistological staging\n",
              "0    56       1  ...                             13                             2\n",
              "1    46       1  ...                              4                             2\n",
              "2    57       1  ...                              4                             4\n",
              "3    49       2  ...                             10                             3\n",
              "4    59       1  ...                             11                             1\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRgCr7rFZrw-",
        "outputId": "216c46a1-66d9-47a2-ed66-b79f9c5a0bdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data[data.columns[13]].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([112132., 129367., 151522., ..., 128354., 205908., 136615.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljiF4KdeQj3x"
      },
      "source": [
        "# changing numerical to categorical ,Discretization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1Z-N5LGPe5v"
      },
      "source": [
        "\n",
        "data[data.columns[0]] = pd.cut(data[data.columns[0]], bins=[0, 32, 37,42,47,52,57,62, float('Inf')], labels=False)#age\n",
        "data[data.columns[2]] = pd.cut(data[data.columns[2]], bins=[0, 18.5, 25,30,35,40, float('Inf')], labels=False)#Bmi\n",
        "data[data.columns[10]] = pd.cut(data[data.columns[10]], bins=[0, 4000, 11000,12101, float('Inf')], labels=False)#WBC\n",
        "data[data.columns[11]] = pd.cut(data[data.columns[11]], bins=[0, 3000000, 5000000,5018451, float('Inf')], labels=False)#RBC\n",
        "\n",
        "if (data[data.columns[1]] == 1).any() :\n",
        "  data[data.columns[12]] = pd.cut(data[data.columns[12]], bins=[2, 14, 17.5,20, float('Inf')], labels=False)#HGB\n",
        "else: \n",
        "  data[data.columns[12]] = pd.cut(data[data.columns[12]], bins=[2, 12.3, 15.3,20, float('Inf')], labels=False)#HGB\n",
        "\n",
        "data[data.columns[13]] = pd.cut(data[data.columns[13]], bins=[93012, 100000, 155001,226465, float('Inf')], labels=False)#PLAT\n",
        "\n",
        "\n",
        "for i in [14,15,16,17,18,19,20,21] :\n",
        "  data[data.columns[i]] = pd.cut(data[data.columns[i]], bins=[0, 20, 40,128, float('Inf')], labels=False)#14-21\n",
        "\n",
        "\n",
        "data[data.columns[22]] = pd.cut(data[data.columns[22]], bins=[0, 6, 1201086, float('Inf')], labels=False)#RNA Base\n",
        "data[data.columns[23]] = pd.cut(data[data.columns[23]], bins=[0, 6, 1201715, float('Inf')], labels=False)#RNA 4\n",
        "data[data.columns[24]] = pd.cut(data[data.columns[24]], bins=[0, 6, 3731527, float('Inf')], labels=False)#RNA 12\n",
        "data[data.columns[25]] = pd.cut(data[data.columns[25]], bins=[0, 6, 808450, float('Inf')], labels=False)#RNA EOT\n",
        "data[data.columns[26]] = pd.cut(data[data.columns[26]], bins=[0, 6, 808450, float('Inf')], labels=False)#RNA EF(Elongation Factor)\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrLTbN-gUAF6",
        "outputId": "2670ec4c-c23a-4657-8b65-2f6ed1d0c0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1385 entries, 0 to 1384\n",
            "Data columns (total 29 columns):\n",
            "Age                                 1385 non-null int64\n",
            "Gender                              1385 non-null int64\n",
            "BMI                                 1385 non-null int64\n",
            "Fever                               1385 non-null int64\n",
            "Nausea/Vomting                      1385 non-null int64\n",
            "Headache                            1385 non-null int64\n",
            "Diarrhea                            1385 non-null int64\n",
            "Fatigue & generalized bone ache     1385 non-null int64\n",
            "Jaundice                            1385 non-null int64\n",
            "Epigastric pain                     1385 non-null int64\n",
            "WBC                                 1385 non-null int64\n",
            "RBC                                 1385 non-null int64\n",
            "HGB                                 1385 non-null int64\n",
            "Plat                                1385 non-null int64\n",
            "AST 1                               1385 non-null int64\n",
            "ALT 1                               1385 non-null int64\n",
            "ALT4                                1385 non-null int64\n",
            "ALT 12                              1385 non-null int64\n",
            "ALT 24                              1385 non-null int64\n",
            "ALT 36                              1385 non-null int64\n",
            "ALT 48                              1385 non-null int64\n",
            "ALT after 24 w                      1385 non-null int64\n",
            "RNA Base                            1385 non-null int64\n",
            "RNA 4                               1385 non-null int64\n",
            "RNA 12                              1385 non-null int64\n",
            "RNA EOT                             1385 non-null int64\n",
            "RNA EF                              1385 non-null int64\n",
            "Baseline histological Grading       1385 non-null int64\n",
            "Baselinehistological staging        1385 non-null int64\n",
            "dtypes: int64(29)\n",
            "memory usage: 313.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tPvZekbUoGe"
      },
      "source": [
        "## Check null and missing value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h33W7fkfUbkm",
        "outputId": "1e3e3eb7-1232-4c68-b25c-e4ed9786a364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "data.isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                                 0\n",
              "Gender                              0\n",
              "BMI                                 0\n",
              "Fever                               0\n",
              "Nausea/Vomting                      0\n",
              "Headache                            0\n",
              "Diarrhea                            0\n",
              "Fatigue & generalized bone ache     0\n",
              "Jaundice                            0\n",
              "Epigastric pain                     0\n",
              "WBC                                 0\n",
              "RBC                                 0\n",
              "HGB                                 0\n",
              "Plat                                0\n",
              "AST 1                               0\n",
              "ALT 1                               0\n",
              "ALT4                                0\n",
              "ALT 12                              0\n",
              "ALT 24                              0\n",
              "ALT 36                              0\n",
              "ALT 48                              0\n",
              "ALT after 24 w                      0\n",
              "RNA Base                            0\n",
              "RNA 4                               0\n",
              "RNA 12                              0\n",
              "RNA EOT                             0\n",
              "RNA EF                              0\n",
              "Baseline histological Grading       0\n",
              "Baselinehistological staging        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vky5Ab6uSaFO",
        "outputId": "f6ca2c3a-66d1-4901-d327-dc885fc809d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40165"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT8DmHZHUhCv",
        "outputId": "95f033c9-cbca-40c7-e18a-9928c699e7db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1385, 29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_7_TQ53U4YL",
        "outputId": "405b1f78-e8c8-4f78-c631-8e6c96871185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "data.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Fever</th>\n",
              "      <th>Nausea/Vomting</th>\n",
              "      <th>Headache</th>\n",
              "      <th>Diarrhea</th>\n",
              "      <th>Fatigue &amp; generalized bone ache</th>\n",
              "      <th>Jaundice</th>\n",
              "      <th>Epigastric pain</th>\n",
              "      <th>WBC</th>\n",
              "      <th>RBC</th>\n",
              "      <th>HGB</th>\n",
              "      <th>Plat</th>\n",
              "      <th>AST 1</th>\n",
              "      <th>ALT 1</th>\n",
              "      <th>ALT4</th>\n",
              "      <th>ALT 12</th>\n",
              "      <th>ALT 24</th>\n",
              "      <th>ALT 36</th>\n",
              "      <th>ALT 48</th>\n",
              "      <th>ALT after 24 w</th>\n",
              "      <th>RNA Base</th>\n",
              "      <th>RNA 4</th>\n",
              "      <th>RNA 12</th>\n",
              "      <th>RNA EOT</th>\n",
              "      <th>RNA EF</th>\n",
              "      <th>Baseline histological Grading</th>\n",
              "      <th>Baselinehistological staging</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.0</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.267870</td>\n",
              "      <td>1.489531</td>\n",
              "      <td>2.085921</td>\n",
              "      <td>1.515523</td>\n",
              "      <td>1.502527</td>\n",
              "      <td>1.496029</td>\n",
              "      <td>1.502527</td>\n",
              "      <td>1.498917</td>\n",
              "      <td>1.501083</td>\n",
              "      <td>1.503971</td>\n",
              "      <td>1.016606</td>\n",
              "      <td>1.020217</td>\n",
              "      <td>0.186282</td>\n",
              "      <td>1.462094</td>\n",
              "      <td>1.976895</td>\n",
              "      <td>1.976895</td>\n",
              "      <td>1.976895</td>\n",
              "      <td>1.975451</td>\n",
              "      <td>1.976173</td>\n",
              "      <td>1.970397</td>\n",
              "      <td>1.976895</td>\n",
              "      <td>1.210108</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.999278</td>\n",
              "      <td>0.722022</td>\n",
              "      <td>0.722744</td>\n",
              "      <td>0.726354</td>\n",
              "      <td>9.761733</td>\n",
              "      <td>2.536462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.775235</td>\n",
              "      <td>0.500071</td>\n",
              "      <td>0.807647</td>\n",
              "      <td>0.499939</td>\n",
              "      <td>0.500174</td>\n",
              "      <td>0.500165</td>\n",
              "      <td>0.500174</td>\n",
              "      <td>0.500179</td>\n",
              "      <td>0.500179</td>\n",
              "      <td>0.500165</td>\n",
              "      <td>0.487279</td>\n",
              "      <td>0.140791</td>\n",
              "      <td>0.389474</td>\n",
              "      <td>0.601215</td>\n",
              "      <td>0.150290</td>\n",
              "      <td>0.150290</td>\n",
              "      <td>0.150290</td>\n",
              "      <td>0.154801</td>\n",
              "      <td>0.152564</td>\n",
              "      <td>0.181886</td>\n",
              "      <td>0.164081</td>\n",
              "      <td>0.412817</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026870</td>\n",
              "      <td>0.448164</td>\n",
              "      <td>0.447806</td>\n",
              "      <td>0.450825</td>\n",
              "      <td>4.023896</td>\n",
              "      <td>1.121392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Age   ...  Baselinehistological staging\n",
              "count  1385.000000  ...                   1385.000000\n",
              "mean      3.267870  ...                      2.536462\n",
              "std       1.775235  ...                      1.121392\n",
              "min       0.000000  ...                      1.000000\n",
              "25%       2.000000  ...                      2.000000\n",
              "50%       3.000000  ...                      3.000000\n",
              "75%       5.000000  ...                      4.000000\n",
              "max       6.000000  ...                      4.000000\n",
              "\n",
              "[8 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkLnHV3-aavs"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ8X27YKY7U5",
        "outputId": "d80f48bd-b949-40cc-89c0-c8cc106a0610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "X = data.iloc[:,0:28]  #independent columns\n",
        "y = data.iloc[:,-1]    #target column i.e price range\n",
        "#apply SelectKBest class to extract top 10 best features\n",
        "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
        "fit = bestfeatures.fit(X,y)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "#concat two dataframes for better visualization \n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
        "print(featureScores.nlargest(10,'Score'))  #print 10 best features\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            Specs     Score\n",
            "27  Baseline histological Grading  5.353347\n",
            "0                            Age   2.572351\n",
            "2                             BMI  2.485752\n",
            "1                          Gender  1.119019\n",
            "9                Epigastric pain   1.089205\n",
            "4                  Nausea/Vomting  0.854361\n",
            "12                            HGB  0.720400\n",
            "8                       Jaundice   0.611780\n",
            "10                            WBC  0.583620\n",
            "26                         RNA EF  0.489587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv0lqmYdS7uV",
        "outputId": "eb895101-31a1-4b44-dde3-cd10341d1d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "X = data.iloc[:,0:28]  #independent columns\n",
        "y = data.iloc[:,-1]    #target column i.e price range\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X,y)\n",
        "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "#plot graph of feature importances for better visualization\n",
        "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(10).plot(kind='barh')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.12383856 0.03211471 0.0738635  0.04247351 0.03645198 0.05862853\n",
            " 0.05375092 0.04976151 0.04550927 0.03742492 0.05556816 0.00661285\n",
            " 0.0397623  0.07157904 0.00552455 0.0087185  0.01000363 0.00730595\n",
            " 0.00736281 0.00730917 0.00888634 0.03979337 0.         0.00028147\n",
            " 0.01191369 0.0104229  0.01271564 0.1424222 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAD4CAYAAACAGr4pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Scj4TwMqO7hX"
      },
      "source": [
        "#  27 Baseline , 0 ge ,  2 BMI , 1 Gender ,  13 Plat, 10 WBC , 6 Diarrhea"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WZm8uQJWbRB"
      },
      "source": [
        "# Cleaning The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8ZK0iDtWegq"
      },
      "source": [
        "data = data[[data.columns[0],data.columns[1],data.columns[2] ,data.columns[6] ,data.columns[10] ,data.columns[13] ,data.columns[27],data.columns[28] ]] \n",
        "df = pd.DataFrame(data, columns = data.columns)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8QjUoz1cWPP"
      },
      "source": [
        "X = df.drop(df.columns[-1] , 1)\n",
        "y = df[df.columns[-1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZxkWfSwiDvX",
        "outputId": "783926b0-0df1-4c5c-938f-8c87a0b263de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y = [x-1 for x in y]\n",
        "#one-hot encode target column\n",
        "y = to_categorical(y)\n",
        "\n",
        "#vcheck that target column has been converted\n",
        "y[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG3dHu_sagZT"
      },
      "source": [
        "# Create training and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2Wiv2J2ctU1"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q1TLfuSac_O"
      },
      "source": [
        "# Feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQwoHbyAaaLN"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        " \n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train),\n",
        "                               columns=X_train.columns,\n",
        "                               index=X_train.index)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test),\n",
        "                           columns=X_test.columns,\n",
        "                           index=X_test.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oD6zlU6aFGp"
      },
      "source": [
        "\n",
        "-\n",
        "\n",
        "-\n",
        "\n",
        "-\n",
        "\n",
        "-\n",
        "\n",
        "-\n",
        "\n",
        "-\n",
        "\n",
        "-\n",
        "\n",
        "-\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYLLuqueaj6m"
      },
      "source": [
        "# Compare each classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6_NdxCZd1oJ",
        "outputId": "cb73d44e-33c3-4834-f34d-6880a2af6f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Logisitic Regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train,y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "#Checking the accuracy\n",
        "logistic_accuracy = round(logreg.score(X_train,y_train)*100,2)\n",
        "print(round(logistic_accuracy,2),'%')\n",
        "\n",
        "\n",
        "scores = cross_val_score(logreg, X, y, cv=5)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-5d5c3d3d83f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Checking the accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1532\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1533\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    722\u001b[0m                         dtype=None)\n\u001b[1;32m    723\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: bad input shape (969, 4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L-cPlGUdwiu",
        "outputId": "1f875e0e-d328-4979-b1d1-8d3b9b57abfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Decesion Tree\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train,y_train)\n",
        "\n",
        "scores = cross_val_score(decision_tree, X, y, cv=5)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "                                       \n",
        "y_pred = decision_tree.predict(X_test)\n",
        "decision_tree_accuracy = round(decision_tree.score(X_train,y_train) * 100,2)\n",
        "print(round(decision_tree_accuracy,2),'%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.21 (+/- 0.04)\n",
            "85.86 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ2c6aSKcydD",
        "outputId": "edbd845a-84f9-4c9e-de11-424878cc0b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Perceptron\n",
        "perceptron = Perceptron(max_iter=5)\n",
        "perceptron.fit(X_train,y_train)\n",
        "\n",
        "y_pred = perceptron.predict(X_test)\n",
        "perceptron_accuracy = round(perceptron.score(X_train,y_train)* 100,2)\n",
        "print(round(perceptron_accuracy,2),'%')\n",
        "\n",
        "scores = cross_val_score(perceptron, X, y, cv=5)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-813438b86d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mperceptron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mperceptron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperceptron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mperceptron_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperceptron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    711\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         X, y = check_X_y(X, y, 'csr', dtype=np.float64, order=\"C\",\n\u001b[0;32m--> 529\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m# labels can be encoded as float, int, or string literals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    722\u001b[0m                         dtype=None)\n\u001b[1;32m    723\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: bad input shape (969, 4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Koov3ITkdG2c",
        "outputId": "6b33d729-d201-4a7a-9ab3-9513e4b6dd79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Randon Forest\n",
        "rand_forest = RandomForestClassifier(n_estimators=100)\n",
        "rand_forest.fit(X_train,y_train)\n",
        "\n",
        "y_pred = rand_forest.predict(X_test)\n",
        "rand_forest_accuracy = round(rand_forest.score(X_train,y_train)*100,2)\n",
        "print(round(rand_forest_accuracy,2),'%')\n",
        "\n",
        "scores = cross_val_score(rand_forest, X, y, cv=5)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93.42 %\n",
            "Accuracy: 0.23 (+/- 0.02)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G96Sc3bgdNHO",
        "outputId": "cf5a7af8-b9ad-4d4d-9f3f-4693010a0cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Naive Bayes\n",
        "gaussian = GaussianNB()\n",
        "gaussian.fit(X_train,y_train)\n",
        "\n",
        "y_pred = gaussian.predict(X_test)\n",
        "gaussian_accuracy = round(gaussian.score(X_train,y_train)*100,2)\n",
        "print(round(gaussian_accuracy,2),'%')\n",
        "\n",
        "scores = cross_val_score(gaussian, X, y, cv=5)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30.96 %\n",
            "Accuracy: 0.24 (+/- 0.04)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYrYH_audT20",
        "outputId": "0d31c227-3dc3-4d35-96d7-fa0615e733f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test)\n",
        "knn_accuracy = round(knn.score(X_train,y_train)*100,2)\n",
        "print(round(knn_accuracy,2),'%')\n",
        "\n",
        "scores = cross_val_score(knn, X, y, cv=5)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55.66 %\n",
            "Accuracy: 0.23 (+/- 0.04)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePMCnxxidaFG",
        "outputId": "c12e4cfb-7644-49f7-ac14-aee76c0e9a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#LinearSVC\n",
        "linear_svc = LinearSVC()\n",
        "linear_svc.fit(X_train,y_train)\n",
        "\n",
        "y_pred = linear_svc.predict(X_test)\n",
        "linear_svc_accuracy = round(linear_svc.score(X_train,y_train)*100,2)\n",
        "print(round(linear_svc_accuracy,2),'%')\n",
        "\n",
        "scores = cross_val_score(linear_svc, X, y, cv=5)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "30.96 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.24 (+/- 0.03)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66WuIecJdf5u",
        "outputId": "cf1961b2-2052-4dc0-d0ad-4f74600b1f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#SVC\n",
        "svc = SVC(gamma='auto')\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "y_pred = svc.predict(X_test)\n",
        "svc_accuracy = round(svc.score(X_train,y_train)*100,2)\n",
        "print(round(svc_accuracy,2),'%')\n",
        "\n",
        "scores = cross_val_score(svc, X, y, cv=5)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45.52 %\n",
            "Accuracy: 0.23 (+/- 0.06)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95PsAfmBauNq"
      },
      "source": [
        "# Compare Classifiers in a table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi7tew-temWx",
        "outputId": "d02a69f7-30af-4a45-ff76-67b484e5beed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "model_evaluation = pd.DataFrame({\n",
        "    'Model':['LogisticRegression','DecisionTreeClassifier','Perceptron','RandomForestClassifier',\n",
        "             \n",
        "             'GaussianNB','KNeighborsClassifier','LinearSVC','SVC'],\n",
        "    \n",
        "    'Score':[logistic_accuracy,decision_tree_accuracy,perceptron_accuracy,rand_forest_accuracy,\n",
        "             gaussian_accuracy,knn_accuracy,linear_svc_accuracy,svc_accuracy,]})\n",
        "model_evaluation.sort_values(by='Score',ascending = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>93.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>93.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>55.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SVC</td>\n",
              "      <td>45.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>30.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>30.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>30.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Perceptron</td>\n",
              "      <td>27.62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Model  Score\n",
              "1  DecisionTreeClassifier  93.42\n",
              "3  RandomForestClassifier  93.42\n",
              "5    KNeighborsClassifier  55.66\n",
              "7                     SVC  45.52\n",
              "4              GaussianNB  30.96\n",
              "6               LinearSVC  30.96\n",
              "0      LogisticRegression  30.74\n",
              "2              Perceptron  27.62"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zBk-MhZfLAn",
        "outputId": "99e1afed-4449-4e22-e0ee-2755dc597dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Diarrhea</th>\n",
              "      <th>WBC</th>\n",
              "      <th>Plat</th>\n",
              "      <th>Baseline histological Grading</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>707</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1139</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>927 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Age   Gender  BMI  Diarrhea   WBC  Plat  Baseline histological Grading\n",
              "260      0       1    2          2    0     2                              5\n",
              "715      1       2    1          2    1     2                              4\n",
              "718      0       1    2          1    1     2                              6\n",
              "707      0       1    3          1    1     2                             10\n",
              "1139     2       1    3          2    0     2                              9\n",
              "...    ...     ...  ...        ...  ...   ...                            ...\n",
              "1095     6       2    1          1    1     1                             12\n",
              "1130     2       2    3          2    2     1                              8\n",
              "1294     2       1    2          1    1     1                              9\n",
              "860      4       2    2          1    1     2                             14\n",
              "1126     4       1    3          1    1     1                              6\n",
              "\n",
              "[927 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHes9ya7az8C"
      },
      "source": [
        "# Building A Deep Learning Model using Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGQqmdZAg1dI",
        "outputId": "4fd2384b-2460-4625-8c79-1d5b07a584a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 3, 0, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eAaDSuQYh5-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivts9IjDZ7nR"
      },
      "source": [
        "def model():\n",
        "    \"\"\"build the Keras model callback\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8, input_dim=7, activation='tanh', name='layer_1'))\n",
        "    model.add(Dense(10, activation='tanh', name='layer_2'))\n",
        "    model.add(Dense(10, activation='tanh', name='layer_3'))\n",
        "    model.add(Dense(4, activation='softmax', name='output_layer'))\n",
        "     \n",
        "    model.compile(loss=\"categorical_crossentropy\",\n",
        "                  optimizer=\"adam\",\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv3lE2cLbc0c"
      },
      "source": [
        "# Do the Model cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_7_eeoUUsCv",
        "outputId": "61d916d8-6a10-4a75-ed58-8023ce425dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "estimator = KerasClassifier(\n",
        "        build_fn=model,\n",
        "        epochs=100, batch_size=20,\n",
        "        verbose=2)\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "results = cross_val_score(estimator, X_train, y_train, cv=kfold )\n",
        "print(\"Model Performance: mean: %.2f%% std: (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " - 3s - loss: 1.4130 - acc: 0.2594\n",
            "Epoch 2/100\n",
            " - 0s - loss: 1.4002 - acc: 0.2477\n",
            "Epoch 3/100\n",
            " - 0s - loss: 1.3922 - acc: 0.2503\n",
            "Epoch 4/100\n",
            " - 0s - loss: 1.3888 - acc: 0.2529\n",
            "Epoch 5/100\n",
            " - 0s - loss: 1.3873 - acc: 0.2723\n",
            "Epoch 6/100\n",
            " - 0s - loss: 1.3857 - acc: 0.2839\n",
            "Epoch 7/100\n",
            " - 0s - loss: 1.3836 - acc: 0.2877\n",
            "Epoch 8/100\n",
            " - 0s - loss: 1.3831 - acc: 0.2787\n",
            "Epoch 9/100\n",
            " - 0s - loss: 1.3838 - acc: 0.2684\n",
            "Epoch 10/100\n",
            " - 0s - loss: 1.3808 - acc: 0.2735\n",
            "Epoch 11/100\n",
            " - 0s - loss: 1.3797 - acc: 0.2839\n",
            "Epoch 12/100\n",
            " - 0s - loss: 1.3801 - acc: 0.2994\n",
            "Epoch 13/100\n",
            " - 0s - loss: 1.3791 - acc: 0.2800\n",
            "Epoch 14/100\n",
            " - 0s - loss: 1.3785 - acc: 0.2890\n",
            "Epoch 15/100\n",
            " - 0s - loss: 1.3794 - acc: 0.2826\n",
            "Epoch 16/100\n",
            " - 0s - loss: 1.3822 - acc: 0.2968\n",
            "Epoch 17/100\n",
            " - 0s - loss: 1.3782 - acc: 0.2942\n",
            "Epoch 18/100\n",
            " - 0s - loss: 1.3778 - acc: 0.2942\n",
            "Epoch 19/100\n",
            " - 0s - loss: 1.3775 - acc: 0.3032\n",
            "Epoch 20/100\n",
            " - 0s - loss: 1.3799 - acc: 0.2839\n",
            "Epoch 21/100\n",
            " - 0s - loss: 1.3775 - acc: 0.2916\n",
            "Epoch 22/100\n",
            " - 0s - loss: 1.3779 - acc: 0.2890\n",
            "Epoch 23/100\n",
            " - 0s - loss: 1.3783 - acc: 0.2981\n",
            "Epoch 24/100\n",
            " - 0s - loss: 1.3767 - acc: 0.3110\n",
            "Epoch 25/100\n",
            " - 0s - loss: 1.3779 - acc: 0.2994\n",
            "Epoch 26/100\n",
            " - 0s - loss: 1.3752 - acc: 0.2929\n",
            "Epoch 27/100\n",
            " - 0s - loss: 1.3762 - acc: 0.3071\n",
            "Epoch 28/100\n",
            " - 0s - loss: 1.3757 - acc: 0.2955\n",
            "Epoch 29/100\n",
            " - 0s - loss: 1.3759 - acc: 0.3045\n",
            "Epoch 30/100\n",
            " - 0s - loss: 1.3751 - acc: 0.2981\n",
            "Epoch 31/100\n",
            " - 0s - loss: 1.3761 - acc: 0.3006\n",
            "Epoch 32/100\n",
            " - 0s - loss: 1.3753 - acc: 0.3084\n",
            "Epoch 33/100\n",
            " - 0s - loss: 1.3757 - acc: 0.2955\n",
            "Epoch 34/100\n",
            " - 0s - loss: 1.3747 - acc: 0.2994\n",
            "Epoch 35/100\n",
            " - 0s - loss: 1.3750 - acc: 0.3058\n",
            "Epoch 36/100\n",
            " - 0s - loss: 1.3767 - acc: 0.2916\n",
            "Epoch 37/100\n",
            " - 0s - loss: 1.3748 - acc: 0.2994\n",
            "Epoch 38/100\n",
            " - 0s - loss: 1.3745 - acc: 0.3045\n",
            "Epoch 39/100\n",
            " - 0s - loss: 1.3736 - acc: 0.3084\n",
            "Epoch 40/100\n",
            " - 0s - loss: 1.3737 - acc: 0.3084\n",
            "Epoch 41/100\n",
            " - 0s - loss: 1.3740 - acc: 0.2968\n",
            "Epoch 42/100\n",
            " - 0s - loss: 1.3733 - acc: 0.3200\n",
            "Epoch 43/100\n",
            " - 0s - loss: 1.3735 - acc: 0.3032\n",
            "Epoch 44/100\n",
            " - 0s - loss: 1.3757 - acc: 0.2865\n",
            "Epoch 45/100\n",
            " - 0s - loss: 1.3749 - acc: 0.2981\n",
            "Epoch 46/100\n",
            " - 0s - loss: 1.3742 - acc: 0.3123\n",
            "Epoch 47/100\n",
            " - 0s - loss: 1.3730 - acc: 0.3006\n",
            "Epoch 48/100\n",
            " - 0s - loss: 1.3730 - acc: 0.3135\n",
            "Epoch 49/100\n",
            " - 0s - loss: 1.3726 - acc: 0.3006\n",
            "Epoch 50/100\n",
            " - 0s - loss: 1.3726 - acc: 0.3097\n",
            "Epoch 51/100\n",
            " - 0s - loss: 1.3735 - acc: 0.2994\n",
            "Epoch 52/100\n",
            " - 0s - loss: 1.3717 - acc: 0.3110\n",
            "Epoch 53/100\n",
            " - 0s - loss: 1.3730 - acc: 0.3006\n",
            "Epoch 54/100\n",
            " - 0s - loss: 1.3718 - acc: 0.3071\n",
            "Epoch 55/100\n",
            " - 0s - loss: 1.3722 - acc: 0.3071\n",
            "Epoch 56/100\n",
            " - 0s - loss: 1.3745 - acc: 0.2942\n",
            "Epoch 57/100\n",
            " - 0s - loss: 1.3713 - acc: 0.3135\n",
            "Epoch 58/100\n",
            " - 0s - loss: 1.3713 - acc: 0.3174\n",
            "Epoch 59/100\n",
            " - 0s - loss: 1.3710 - acc: 0.3135\n",
            "Epoch 60/100\n",
            " - 0s - loss: 1.3714 - acc: 0.2981\n",
            "Epoch 61/100\n",
            " - 0s - loss: 1.3706 - acc: 0.3071\n",
            "Epoch 62/100\n",
            " - 0s - loss: 1.3710 - acc: 0.3213\n",
            "Epoch 63/100\n",
            " - 0s - loss: 1.3713 - acc: 0.2968\n",
            "Epoch 64/100\n",
            " - 0s - loss: 1.3707 - acc: 0.2981\n",
            "Epoch 65/100\n",
            " - 0s - loss: 1.3714 - acc: 0.2929\n",
            "Epoch 66/100\n",
            " - 0s - loss: 1.3708 - acc: 0.3019\n",
            "Epoch 67/100\n",
            " - 0s - loss: 1.3695 - acc: 0.2994\n",
            "Epoch 68/100\n",
            " - 0s - loss: 1.3725 - acc: 0.2916\n",
            "Epoch 69/100\n",
            " - 0s - loss: 1.3724 - acc: 0.2968\n",
            "Epoch 70/100\n",
            " - 0s - loss: 1.3697 - acc: 0.3071\n",
            "Epoch 71/100\n",
            " - 0s - loss: 1.3709 - acc: 0.3045\n",
            "Epoch 72/100\n",
            " - 0s - loss: 1.3704 - acc: 0.3045\n",
            "Epoch 73/100\n",
            " - 0s - loss: 1.3695 - acc: 0.3058\n",
            "Epoch 74/100\n",
            " - 0s - loss: 1.3690 - acc: 0.3097\n",
            "Epoch 75/100\n",
            " - 0s - loss: 1.3690 - acc: 0.3058\n",
            "Epoch 76/100\n",
            " - 0s - loss: 1.3685 - acc: 0.3174\n",
            "Epoch 77/100\n",
            " - 0s - loss: 1.3697 - acc: 0.3058\n",
            "Epoch 78/100\n",
            " - 0s - loss: 1.3683 - acc: 0.3174\n",
            "Epoch 79/100\n",
            " - 0s - loss: 1.3676 - acc: 0.2994\n",
            "Epoch 80/100\n",
            " - 0s - loss: 1.3692 - acc: 0.3045\n",
            "Epoch 81/100\n",
            " - 0s - loss: 1.3683 - acc: 0.3148\n",
            "Epoch 82/100\n",
            " - 0s - loss: 1.3687 - acc: 0.3187\n",
            "Epoch 83/100\n",
            " - 0s - loss: 1.3676 - acc: 0.3161\n",
            "Epoch 84/100\n",
            " - 0s - loss: 1.3696 - acc: 0.3071\n",
            "Epoch 85/100\n",
            " - 0s - loss: 1.3675 - acc: 0.3032\n",
            "Epoch 86/100\n",
            " - 0s - loss: 1.3670 - acc: 0.3123\n",
            "Epoch 87/100\n",
            " - 0s - loss: 1.3671 - acc: 0.3071\n",
            "Epoch 88/100\n",
            " - 0s - loss: 1.3675 - acc: 0.2981\n",
            "Epoch 89/100\n",
            " - 0s - loss: 1.3672 - acc: 0.3110\n",
            "Epoch 90/100\n",
            " - 0s - loss: 1.3666 - acc: 0.3097\n",
            "Epoch 91/100\n",
            " - 0s - loss: 1.3673 - acc: 0.3084\n",
            "Epoch 92/100\n",
            " - 0s - loss: 1.3689 - acc: 0.3123\n",
            "Epoch 93/100\n",
            " - 0s - loss: 1.3689 - acc: 0.3097\n",
            "Epoch 94/100\n",
            " - 0s - loss: 1.3669 - acc: 0.3174\n",
            "Epoch 95/100\n",
            " - 0s - loss: 1.3661 - acc: 0.3161\n",
            "Epoch 96/100\n",
            " - 0s - loss: 1.3661 - acc: 0.3058\n",
            "Epoch 97/100\n",
            " - 0s - loss: 1.3649 - acc: 0.3161\n",
            "Epoch 98/100\n",
            " - 0s - loss: 1.3667 - acc: 0.3148\n",
            "Epoch 99/100\n",
            " - 0s - loss: 1.3650 - acc: 0.3148\n",
            "Epoch 100/100\n",
            " - 0s - loss: 1.3662 - acc: 0.3187\n",
            "Epoch 1/100\n",
            " - 3s - loss: 1.4423 - acc: 0.2555\n",
            "Epoch 2/100\n",
            " - 0s - loss: 1.4068 - acc: 0.2555\n",
            "Epoch 3/100\n",
            " - 0s - loss: 1.3989 - acc: 0.2477\n",
            "Epoch 4/100\n",
            " - 0s - loss: 1.3943 - acc: 0.2387\n",
            "Epoch 5/100\n",
            " - 0s - loss: 1.3912 - acc: 0.2542\n",
            "Epoch 6/100\n",
            " - 0s - loss: 1.3884 - acc: 0.2684\n",
            "Epoch 7/100\n",
            " - 0s - loss: 1.3871 - acc: 0.2516\n",
            "Epoch 8/100\n",
            " - 0s - loss: 1.3858 - acc: 0.2348\n",
            "Epoch 9/100\n",
            " - 0s - loss: 1.3848 - acc: 0.2632\n",
            "Epoch 10/100\n",
            " - 0s - loss: 1.3839 - acc: 0.2555\n",
            "Epoch 11/100\n",
            " - 0s - loss: 1.3835 - acc: 0.2594\n",
            "Epoch 12/100\n",
            " - 0s - loss: 1.3829 - acc: 0.2555\n",
            "Epoch 13/100\n",
            " - 0s - loss: 1.3814 - acc: 0.2645\n",
            "Epoch 14/100\n",
            " - 0s - loss: 1.3810 - acc: 0.2735\n",
            "Epoch 15/100\n",
            " - 0s - loss: 1.3812 - acc: 0.2581\n",
            "Epoch 16/100\n",
            " - 0s - loss: 1.3802 - acc: 0.2684\n",
            "Epoch 17/100\n",
            " - 0s - loss: 1.3807 - acc: 0.2684\n",
            "Epoch 18/100\n",
            " - 0s - loss: 1.3803 - acc: 0.2684\n",
            "Epoch 19/100\n",
            " - 0s - loss: 1.3802 - acc: 0.2632\n",
            "Epoch 20/100\n",
            " - 0s - loss: 1.3794 - acc: 0.2813\n",
            "Epoch 21/100\n",
            " - 0s - loss: 1.3805 - acc: 0.2697\n",
            "Epoch 22/100\n",
            " - 0s - loss: 1.3797 - acc: 0.2710\n",
            "Epoch 23/100\n",
            " - 0s - loss: 1.3789 - acc: 0.2632\n",
            "Epoch 24/100\n",
            " - 0s - loss: 1.3791 - acc: 0.2826\n",
            "Epoch 25/100\n",
            " - 0s - loss: 1.3785 - acc: 0.2671\n",
            "Epoch 26/100\n",
            " - 0s - loss: 1.3792 - acc: 0.2658\n",
            "Epoch 27/100\n",
            " - 0s - loss: 1.3789 - acc: 0.2658\n",
            "Epoch 28/100\n",
            " - 0s - loss: 1.3812 - acc: 0.2658\n",
            "Epoch 29/100\n",
            " - 0s - loss: 1.3790 - acc: 0.2671\n",
            "Epoch 30/100\n",
            " - 0s - loss: 1.3785 - acc: 0.2658\n",
            "Epoch 31/100\n",
            " - 0s - loss: 1.3788 - acc: 0.2684\n",
            "Epoch 32/100\n",
            " - 0s - loss: 1.3775 - acc: 0.2761\n",
            "Epoch 33/100\n",
            " - 0s - loss: 1.3775 - acc: 0.2826\n",
            "Epoch 34/100\n",
            " - 0s - loss: 1.3778 - acc: 0.2723\n",
            "Epoch 35/100\n",
            " - 0s - loss: 1.3781 - acc: 0.2658\n",
            "Epoch 36/100\n",
            " - 0s - loss: 1.3799 - acc: 0.2581\n",
            "Epoch 37/100\n",
            " - 0s - loss: 1.3777 - acc: 0.2684\n",
            "Epoch 38/100\n",
            " - 0s - loss: 1.3769 - acc: 0.2787\n",
            "Epoch 39/100\n",
            " - 0s - loss: 1.3778 - acc: 0.2748\n",
            "Epoch 40/100\n",
            " - 0s - loss: 1.3768 - acc: 0.2710\n",
            "Epoch 41/100\n",
            " - 0s - loss: 1.3775 - acc: 0.2645\n",
            "Epoch 42/100\n",
            " - 0s - loss: 1.3768 - acc: 0.2710\n",
            "Epoch 43/100\n",
            " - 0s - loss: 1.3775 - acc: 0.2671\n",
            "Epoch 44/100\n",
            " - 0s - loss: 1.3775 - acc: 0.2723\n",
            "Epoch 45/100\n",
            " - 0s - loss: 1.3772 - acc: 0.2735\n",
            "Epoch 46/100\n",
            " - 0s - loss: 1.3770 - acc: 0.2787\n",
            "Epoch 47/100\n",
            " - 0s - loss: 1.3767 - acc: 0.2813\n",
            "Epoch 48/100\n",
            " - 0s - loss: 1.3771 - acc: 0.2658\n",
            "Epoch 49/100\n",
            " - 0s - loss: 1.3761 - acc: 0.2826\n",
            "Epoch 50/100\n",
            " - 0s - loss: 1.3764 - acc: 0.2748\n",
            "Epoch 51/100\n",
            " - 0s - loss: 1.3776 - acc: 0.2542\n",
            "Epoch 52/100\n",
            " - 0s - loss: 1.3767 - acc: 0.2697\n",
            "Epoch 53/100\n",
            " - 0s - loss: 1.3753 - acc: 0.2658\n",
            "Epoch 54/100\n",
            " - 0s - loss: 1.3761 - acc: 0.2658\n",
            "Epoch 55/100\n",
            " - 0s - loss: 1.3785 - acc: 0.2813\n",
            "Epoch 56/100\n",
            " - 0s - loss: 1.3753 - acc: 0.2684\n",
            "Epoch 57/100\n",
            " - 0s - loss: 1.3757 - acc: 0.2671\n",
            "Epoch 58/100\n",
            " - 0s - loss: 1.3764 - acc: 0.2942\n",
            "Epoch 59/100\n",
            " - 0s - loss: 1.3760 - acc: 0.2839\n",
            "Epoch 60/100\n",
            " - 0s - loss: 1.3755 - acc: 0.2865\n",
            "Epoch 61/100\n",
            " - 0s - loss: 1.3766 - acc: 0.2748\n",
            "Epoch 62/100\n",
            " - 0s - loss: 1.3745 - acc: 0.2877\n",
            "Epoch 63/100\n",
            " - 0s - loss: 1.3742 - acc: 0.2710\n",
            "Epoch 64/100\n",
            " - 0s - loss: 1.3747 - acc: 0.2619\n",
            "Epoch 65/100\n",
            " - 0s - loss: 1.3745 - acc: 0.2826\n",
            "Epoch 66/100\n",
            " - 0s - loss: 1.3749 - acc: 0.2787\n",
            "Epoch 67/100\n",
            " - 0s - loss: 1.3750 - acc: 0.2929\n",
            "Epoch 68/100\n",
            " - 0s - loss: 1.3751 - acc: 0.2568\n",
            "Epoch 69/100\n",
            " - 0s - loss: 1.3738 - acc: 0.2968\n",
            "Epoch 70/100\n",
            " - 0s - loss: 1.3740 - acc: 0.2774\n",
            "Epoch 71/100\n",
            " - 0s - loss: 1.3744 - acc: 0.2826\n",
            "Epoch 72/100\n",
            " - 0s - loss: 1.3744 - acc: 0.3006\n",
            "Epoch 73/100\n",
            " - 0s - loss: 1.3739 - acc: 0.2748\n",
            "Epoch 74/100\n",
            " - 0s - loss: 1.3736 - acc: 0.2671\n",
            "Epoch 75/100\n",
            " - 0s - loss: 1.3733 - acc: 0.2903\n",
            "Epoch 76/100\n",
            " - 0s - loss: 1.3732 - acc: 0.2981\n",
            "Epoch 77/100\n",
            " - 0s - loss: 1.3742 - acc: 0.2903\n",
            "Epoch 78/100\n",
            " - 0s - loss: 1.3729 - acc: 0.2852\n",
            "Epoch 79/100\n",
            " - 0s - loss: 1.3733 - acc: 0.2735\n",
            "Epoch 80/100\n",
            " - 0s - loss: 1.3731 - acc: 0.2994\n",
            "Epoch 81/100\n",
            " - 0s - loss: 1.3741 - acc: 0.2761\n",
            "Epoch 82/100\n",
            " - 0s - loss: 1.3724 - acc: 0.2916\n",
            "Epoch 83/100\n",
            " - 0s - loss: 1.3730 - acc: 0.2942\n",
            "Epoch 84/100\n",
            " - 0s - loss: 1.3725 - acc: 0.2929\n",
            "Epoch 85/100\n",
            " - 0s - loss: 1.3723 - acc: 0.2981\n",
            "Epoch 86/100\n",
            " - 0s - loss: 1.3715 - acc: 0.3032\n",
            "Epoch 87/100\n",
            " - 0s - loss: 1.3719 - acc: 0.2981\n",
            "Epoch 88/100\n",
            " - 0s - loss: 1.3724 - acc: 0.2761\n",
            "Epoch 89/100\n",
            " - 0s - loss: 1.3715 - acc: 0.3006\n",
            "Epoch 90/100\n",
            " - 0s - loss: 1.3719 - acc: 0.3006\n",
            "Epoch 91/100\n",
            " - 0s - loss: 1.3720 - acc: 0.2955\n",
            "Epoch 92/100\n",
            " - 0s - loss: 1.3728 - acc: 0.2813\n",
            "Epoch 93/100\n",
            " - 0s - loss: 1.3718 - acc: 0.2994\n",
            "Epoch 94/100\n",
            " - 0s - loss: 1.3708 - acc: 0.2955\n",
            "Epoch 95/100\n",
            " - 0s - loss: 1.3706 - acc: 0.2890\n",
            "Epoch 96/100\n",
            " - 0s - loss: 1.3716 - acc: 0.2942\n",
            "Epoch 97/100\n",
            " - 0s - loss: 1.3704 - acc: 0.2916\n",
            "Epoch 98/100\n",
            " - 0s - loss: 1.3701 - acc: 0.2994\n",
            "Epoch 99/100\n",
            " - 0s - loss: 1.3720 - acc: 0.3019\n",
            "Epoch 100/100\n",
            " - 0s - loss: 1.3705 - acc: 0.2929\n",
            "Epoch 1/100\n",
            " - 3s - loss: 1.4261 - acc: 0.2348\n",
            "Epoch 2/100\n",
            " - 0s - loss: 1.4000 - acc: 0.2439\n",
            "Epoch 3/100\n",
            " - 0s - loss: 1.3970 - acc: 0.2619\n",
            "Epoch 4/100\n",
            " - 0s - loss: 1.3932 - acc: 0.2568\n",
            "Epoch 5/100\n",
            " - 0s - loss: 1.3918 - acc: 0.2542\n",
            "Epoch 6/100\n",
            " - 0s - loss: 1.3890 - acc: 0.2516\n",
            "Epoch 7/100\n",
            " - 0s - loss: 1.3882 - acc: 0.2529\n",
            "Epoch 8/100\n",
            " - 0s - loss: 1.3859 - acc: 0.2542\n",
            "Epoch 9/100\n",
            " - 0s - loss: 1.3855 - acc: 0.2658\n",
            "Epoch 10/100\n",
            " - 0s - loss: 1.3846 - acc: 0.2671\n",
            "Epoch 11/100\n",
            " - 0s - loss: 1.3840 - acc: 0.2619\n",
            "Epoch 12/100\n",
            " - 0s - loss: 1.3832 - acc: 0.2658\n",
            "Epoch 13/100\n",
            " - 0s - loss: 1.3822 - acc: 0.2748\n",
            "Epoch 14/100\n",
            " - 0s - loss: 1.3823 - acc: 0.2981\n",
            "Epoch 15/100\n",
            " - 0s - loss: 1.3809 - acc: 0.2813\n",
            "Epoch 16/100\n",
            " - 0s - loss: 1.3809 - acc: 0.2787\n",
            "Epoch 17/100\n",
            " - 0s - loss: 1.3799 - acc: 0.2774\n",
            "Epoch 18/100\n",
            " - 0s - loss: 1.3795 - acc: 0.2903\n",
            "Epoch 19/100\n",
            " - 0s - loss: 1.3804 - acc: 0.2735\n",
            "Epoch 20/100\n",
            " - 0s - loss: 1.3790 - acc: 0.2813\n",
            "Epoch 21/100\n",
            " - 0s - loss: 1.3783 - acc: 0.2735\n",
            "Epoch 22/100\n",
            " - 0s - loss: 1.3786 - acc: 0.2968\n",
            "Epoch 23/100\n",
            " - 0s - loss: 1.3778 - acc: 0.2645\n",
            "Epoch 24/100\n",
            " - 0s - loss: 1.3780 - acc: 0.2761\n",
            "Epoch 25/100\n",
            " - 0s - loss: 1.3780 - acc: 0.2723\n",
            "Epoch 26/100\n",
            " - 0s - loss: 1.3768 - acc: 0.2813\n",
            "Epoch 27/100\n",
            " - 0s - loss: 1.3765 - acc: 0.2787\n",
            "Epoch 28/100\n",
            " - 0s - loss: 1.3766 - acc: 0.2865\n",
            "Epoch 29/100\n",
            " - 0s - loss: 1.3770 - acc: 0.2865\n",
            "Epoch 30/100\n",
            " - 0s - loss: 1.3761 - acc: 0.2606\n",
            "Epoch 31/100\n",
            " - 0s - loss: 1.3762 - acc: 0.2761\n",
            "Epoch 32/100\n",
            " - 0s - loss: 1.3757 - acc: 0.2671\n",
            "Epoch 33/100\n",
            " - 0s - loss: 1.3747 - acc: 0.2774\n",
            "Epoch 34/100\n",
            " - 0s - loss: 1.3757 - acc: 0.2865\n",
            "Epoch 35/100\n",
            " - 0s - loss: 1.3762 - acc: 0.2826\n",
            "Epoch 36/100\n",
            " - 0s - loss: 1.3749 - acc: 0.2787\n",
            "Epoch 37/100\n",
            " - 0s - loss: 1.3756 - acc: 0.2839\n",
            "Epoch 38/100\n",
            " - 0s - loss: 1.3756 - acc: 0.2800\n",
            "Epoch 39/100\n",
            " - 0s - loss: 1.3740 - acc: 0.2826\n",
            "Epoch 40/100\n",
            " - 0s - loss: 1.3744 - acc: 0.2890\n",
            "Epoch 41/100\n",
            " - 0s - loss: 1.3735 - acc: 0.2890\n",
            "Epoch 42/100\n",
            " - 0s - loss: 1.3751 - acc: 0.2877\n",
            "Epoch 43/100\n",
            " - 0s - loss: 1.3743 - acc: 0.2800\n",
            "Epoch 44/100\n",
            " - 0s - loss: 1.3746 - acc: 0.2748\n",
            "Epoch 45/100\n",
            " - 0s - loss: 1.3739 - acc: 0.2813\n",
            "Epoch 46/100\n",
            " - 0s - loss: 1.3737 - acc: 0.2916\n",
            "Epoch 47/100\n",
            " - 0s - loss: 1.3738 - acc: 0.2800\n",
            "Epoch 48/100\n",
            " - 0s - loss: 1.3729 - acc: 0.2826\n",
            "Epoch 49/100\n",
            " - 0s - loss: 1.3741 - acc: 0.2800\n",
            "Epoch 50/100\n",
            " - 0s - loss: 1.3747 - acc: 0.2710\n",
            "Epoch 51/100\n",
            " - 0s - loss: 1.3727 - acc: 0.2877\n",
            "Epoch 52/100\n",
            " - 0s - loss: 1.3743 - acc: 0.2852\n",
            "Epoch 53/100\n",
            " - 0s - loss: 1.3727 - acc: 0.2916\n",
            "Epoch 54/100\n",
            " - 0s - loss: 1.3724 - acc: 0.2813\n",
            "Epoch 55/100\n",
            " - 0s - loss: 1.3732 - acc: 0.2748\n",
            "Epoch 56/100\n",
            " - 0s - loss: 1.3725 - acc: 0.2839\n",
            "Epoch 57/100\n",
            " - 0s - loss: 1.3739 - acc: 0.2748\n",
            "Epoch 58/100\n",
            " - 0s - loss: 1.3734 - acc: 0.2826\n",
            "Epoch 59/100\n",
            " - 0s - loss: 1.3722 - acc: 0.2877\n",
            "Epoch 60/100\n",
            " - 0s - loss: 1.3725 - acc: 0.2787\n",
            "Epoch 61/100\n",
            " - 0s - loss: 1.3723 - acc: 0.2890\n",
            "Epoch 62/100\n",
            " - 0s - loss: 1.3729 - acc: 0.2826\n",
            "Epoch 63/100\n",
            " - 0s - loss: 1.3717 - acc: 0.2877\n",
            "Epoch 64/100\n",
            " - 0s - loss: 1.3713 - acc: 0.2955\n",
            "Epoch 65/100\n",
            " - 0s - loss: 1.3718 - acc: 0.2723\n",
            "Epoch 66/100\n",
            " - 0s - loss: 1.3721 - acc: 0.2800\n",
            "Epoch 67/100\n",
            " - 0s - loss: 1.3732 - acc: 0.2723\n",
            "Epoch 68/100\n",
            " - 0s - loss: 1.3735 - acc: 0.2645\n",
            "Epoch 69/100\n",
            " - 0s - loss: 1.3715 - acc: 0.2852\n",
            "Epoch 70/100\n",
            " - 0s - loss: 1.3716 - acc: 0.2774\n",
            "Epoch 71/100\n",
            " - 0s - loss: 1.3717 - acc: 0.2929\n",
            "Epoch 72/100\n",
            " - 0s - loss: 1.3712 - acc: 0.2852\n",
            "Epoch 73/100\n",
            " - 0s - loss: 1.3719 - acc: 0.2813\n",
            "Epoch 74/100\n",
            " - 0s - loss: 1.3718 - acc: 0.2761\n",
            "Epoch 75/100\n",
            " - 0s - loss: 1.3721 - acc: 0.2735\n",
            "Epoch 76/100\n",
            " - 0s - loss: 1.3724 - acc: 0.2826\n",
            "Epoch 77/100\n",
            " - 0s - loss: 1.3718 - acc: 0.2955\n",
            "Epoch 78/100\n",
            " - 0s - loss: 1.3708 - acc: 0.2916\n",
            "Epoch 79/100\n",
            " - 0s - loss: 1.3711 - acc: 0.2839\n",
            "Epoch 80/100\n",
            " - 0s - loss: 1.3714 - acc: 0.2865\n",
            "Epoch 81/100\n",
            " - 0s - loss: 1.3724 - acc: 0.2865\n",
            "Epoch 82/100\n",
            " - 0s - loss: 1.3710 - acc: 0.2839\n",
            "Epoch 83/100\n",
            " - 0s - loss: 1.3717 - acc: 0.2787\n",
            "Epoch 84/100\n",
            " - 0s - loss: 1.3715 - acc: 0.2865\n",
            "Epoch 85/100\n",
            " - 0s - loss: 1.3707 - acc: 0.2890\n",
            "Epoch 86/100\n",
            " - 0s - loss: 1.3706 - acc: 0.2877\n",
            "Epoch 87/100\n",
            " - 0s - loss: 1.3713 - acc: 0.2761\n",
            "Epoch 88/100\n",
            " - 0s - loss: 1.3702 - acc: 0.2787\n",
            "Epoch 89/100\n",
            " - 0s - loss: 1.3714 - acc: 0.2852\n",
            "Epoch 90/100\n",
            " - 0s - loss: 1.3716 - acc: 0.2865\n",
            "Epoch 91/100\n",
            " - 0s - loss: 1.3720 - acc: 0.2839\n",
            "Epoch 92/100\n",
            " - 0s - loss: 1.3724 - acc: 0.2684\n",
            "Epoch 93/100\n",
            " - 0s - loss: 1.3718 - acc: 0.2839\n",
            "Epoch 94/100\n",
            " - 0s - loss: 1.3706 - acc: 0.2877\n",
            "Epoch 95/100\n",
            " - 0s - loss: 1.3709 - acc: 0.2800\n",
            "Epoch 96/100\n",
            " - 0s - loss: 1.3703 - acc: 0.2916\n",
            "Epoch 97/100\n",
            " - 0s - loss: 1.3705 - acc: 0.2774\n",
            "Epoch 98/100\n",
            " - 0s - loss: 1.3710 - acc: 0.2826\n",
            "Epoch 99/100\n",
            " - 0s - loss: 1.3700 - acc: 0.2955\n",
            "Epoch 100/100\n",
            " - 0s - loss: 1.3711 - acc: 0.2813\n",
            "Epoch 1/100\n",
            " - 3s - loss: 1.4018 - acc: 0.2555\n",
            "Epoch 2/100\n",
            " - 0s - loss: 1.3891 - acc: 0.2735\n",
            "Epoch 3/100\n",
            " - 0s - loss: 1.3892 - acc: 0.2581\n",
            "Epoch 4/100\n",
            " - 0s - loss: 1.3866 - acc: 0.2723\n",
            "Epoch 5/100\n",
            " - 0s - loss: 1.3859 - acc: 0.2606\n",
            "Epoch 6/100\n",
            " - 0s - loss: 1.3852 - acc: 0.2606\n",
            "Epoch 7/100\n",
            " - 0s - loss: 1.3855 - acc: 0.2555\n",
            "Epoch 8/100\n",
            " - 0s - loss: 1.3848 - acc: 0.2606\n",
            "Epoch 9/100\n",
            " - 0s - loss: 1.3843 - acc: 0.2658\n",
            "Epoch 10/100\n",
            " - 0s - loss: 1.3843 - acc: 0.2723\n",
            "Epoch 11/100\n",
            " - 0s - loss: 1.3846 - acc: 0.2619\n",
            "Epoch 12/100\n",
            " - 0s - loss: 1.3846 - acc: 0.2632\n",
            "Epoch 13/100\n",
            " - 0s - loss: 1.3833 - acc: 0.2800\n",
            "Epoch 14/100\n",
            " - 0s - loss: 1.3829 - acc: 0.2645\n",
            "Epoch 15/100\n",
            " - 0s - loss: 1.3830 - acc: 0.2761\n",
            "Epoch 16/100\n",
            " - 0s - loss: 1.3834 - acc: 0.2813\n",
            "Epoch 17/100\n",
            " - 0s - loss: 1.3828 - acc: 0.2813\n",
            "Epoch 18/100\n",
            " - 0s - loss: 1.3823 - acc: 0.2826\n",
            "Epoch 19/100\n",
            " - 0s - loss: 1.3824 - acc: 0.2723\n",
            "Epoch 20/100\n",
            " - 0s - loss: 1.3816 - acc: 0.2761\n",
            "Epoch 21/100\n",
            " - 0s - loss: 1.3829 - acc: 0.2787\n",
            "Epoch 22/100\n",
            " - 0s - loss: 1.3818 - acc: 0.2774\n",
            "Epoch 23/100\n",
            " - 0s - loss: 1.3807 - acc: 0.2710\n",
            "Epoch 24/100\n",
            " - 0s - loss: 1.3811 - acc: 0.2865\n",
            "Epoch 25/100\n",
            " - 0s - loss: 1.3822 - acc: 0.2968\n",
            "Epoch 26/100\n",
            " - 0s - loss: 1.3810 - acc: 0.2710\n",
            "Epoch 27/100\n",
            " - 0s - loss: 1.3822 - acc: 0.2710\n",
            "Epoch 28/100\n",
            " - 0s - loss: 1.3798 - acc: 0.2658\n",
            "Epoch 29/100\n",
            " - 0s - loss: 1.3815 - acc: 0.2826\n",
            "Epoch 30/100\n",
            " - 0s - loss: 1.3801 - acc: 0.2761\n",
            "Epoch 31/100\n",
            " - 0s - loss: 1.3803 - acc: 0.2852\n",
            "Epoch 32/100\n",
            " - 0s - loss: 1.3797 - acc: 0.2710\n",
            "Epoch 33/100\n",
            " - 0s - loss: 1.3792 - acc: 0.2890\n",
            "Epoch 34/100\n",
            " - 0s - loss: 1.3795 - acc: 0.2865\n",
            "Epoch 35/100\n",
            " - 0s - loss: 1.3787 - acc: 0.2826\n",
            "Epoch 36/100\n",
            " - 0s - loss: 1.3790 - acc: 0.2916\n",
            "Epoch 37/100\n",
            " - 0s - loss: 1.3786 - acc: 0.2839\n",
            "Epoch 38/100\n",
            " - 0s - loss: 1.3788 - acc: 0.2826\n",
            "Epoch 39/100\n",
            " - 0s - loss: 1.3785 - acc: 0.2787\n",
            "Epoch 40/100\n",
            " - 0s - loss: 1.3784 - acc: 0.2903\n",
            "Epoch 41/100\n",
            " - 0s - loss: 1.3778 - acc: 0.2826\n",
            "Epoch 42/100\n",
            " - 0s - loss: 1.3781 - acc: 0.2800\n",
            "Epoch 43/100\n",
            " - 0s - loss: 1.3784 - acc: 0.2852\n",
            "Epoch 44/100\n",
            " - 0s - loss: 1.3778 - acc: 0.2761\n",
            "Epoch 45/100\n",
            " - 0s - loss: 1.3767 - acc: 0.2955\n",
            "Epoch 46/100\n",
            " - 0s - loss: 1.3776 - acc: 0.2735\n",
            "Epoch 47/100\n",
            " - 0s - loss: 1.3775 - acc: 0.2787\n",
            "Epoch 48/100\n",
            " - 0s - loss: 1.3767 - acc: 0.2839\n",
            "Epoch 49/100\n",
            " - 0s - loss: 1.3774 - acc: 0.2903\n",
            "Epoch 50/100\n",
            " - 0s - loss: 1.3764 - acc: 0.2813\n",
            "Epoch 51/100\n",
            " - 0s - loss: 1.3766 - acc: 0.2903\n",
            "Epoch 52/100\n",
            " - 0s - loss: 1.3770 - acc: 0.2697\n",
            "Epoch 53/100\n",
            " - 0s - loss: 1.3761 - acc: 0.2813\n",
            "Epoch 54/100\n",
            " - 0s - loss: 1.3767 - acc: 0.2877\n",
            "Epoch 55/100\n",
            " - 0s - loss: 1.3764 - acc: 0.2800\n",
            "Epoch 56/100\n",
            " - 0s - loss: 1.3759 - acc: 0.2735\n",
            "Epoch 57/100\n",
            " - 0s - loss: 1.3764 - acc: 0.2890\n",
            "Epoch 58/100\n",
            " - 0s - loss: 1.3756 - acc: 0.2839\n",
            "Epoch 59/100\n",
            " - 0s - loss: 1.3751 - acc: 0.2839\n",
            "Epoch 60/100\n",
            " - 0s - loss: 1.3766 - acc: 0.2710\n",
            "Epoch 61/100\n",
            " - 0s - loss: 1.3770 - acc: 0.2735\n",
            "Epoch 62/100\n",
            " - 0s - loss: 1.3760 - acc: 0.2774\n",
            "Epoch 63/100\n",
            " - 0s - loss: 1.3755 - acc: 0.2852\n",
            "Epoch 64/100\n",
            " - 0s - loss: 1.3761 - acc: 0.2774\n",
            "Epoch 65/100\n",
            " - 0s - loss: 1.3773 - acc: 0.2839\n",
            "Epoch 66/100\n",
            " - 0s - loss: 1.3753 - acc: 0.2826\n",
            "Epoch 67/100\n",
            " - 0s - loss: 1.3737 - acc: 0.2916\n",
            "Epoch 68/100\n",
            " - 0s - loss: 1.3744 - acc: 0.2774\n",
            "Epoch 69/100\n",
            " - 0s - loss: 1.3743 - acc: 0.2916\n",
            "Epoch 70/100\n",
            " - 0s - loss: 1.3754 - acc: 0.2826\n",
            "Epoch 71/100\n",
            " - 0s - loss: 1.3752 - acc: 0.2955\n",
            "Epoch 72/100\n",
            " - 0s - loss: 1.3745 - acc: 0.2852\n",
            "Epoch 73/100\n",
            " - 0s - loss: 1.3747 - acc: 0.2890\n",
            "Epoch 74/100\n",
            " - 0s - loss: 1.3741 - acc: 0.2826\n",
            "Epoch 75/100\n",
            " - 0s - loss: 1.3753 - acc: 0.2877\n",
            "Epoch 76/100\n",
            " - 0s - loss: 1.3736 - acc: 0.2865\n",
            "Epoch 77/100\n",
            " - 0s - loss: 1.3760 - acc: 0.2981\n",
            "Epoch 78/100\n",
            " - 0s - loss: 1.3748 - acc: 0.2787\n",
            "Epoch 79/100\n",
            " - 0s - loss: 1.3730 - acc: 0.2813\n",
            "Epoch 80/100\n",
            " - 0s - loss: 1.3735 - acc: 0.2839\n",
            "Epoch 81/100\n",
            " - 0s - loss: 1.3745 - acc: 0.2955\n",
            "Epoch 82/100\n",
            " - 0s - loss: 1.3729 - acc: 0.2890\n",
            "Epoch 83/100\n",
            " - 0s - loss: 1.3733 - acc: 0.3019\n",
            "Epoch 84/100\n",
            " - 0s - loss: 1.3723 - acc: 0.2826\n",
            "Epoch 85/100\n",
            " - 0s - loss: 1.3739 - acc: 0.2852\n",
            "Epoch 86/100\n",
            " - 0s - loss: 1.3726 - acc: 0.2839\n",
            "Epoch 87/100\n",
            " - 0s - loss: 1.3726 - acc: 0.2916\n",
            "Epoch 88/100\n",
            " - 0s - loss: 1.3734 - acc: 0.2968\n",
            "Epoch 89/100\n",
            " - 0s - loss: 1.3737 - acc: 0.2890\n",
            "Epoch 90/100\n",
            " - 0s - loss: 1.3733 - acc: 0.2826\n",
            "Epoch 91/100\n",
            " - 0s - loss: 1.3722 - acc: 0.2865\n",
            "Epoch 92/100\n",
            " - 0s - loss: 1.3725 - acc: 0.2839\n",
            "Epoch 93/100\n",
            " - 0s - loss: 1.3724 - acc: 0.2903\n",
            "Epoch 94/100\n",
            " - 0s - loss: 1.3726 - acc: 0.2748\n",
            "Epoch 95/100\n",
            " - 0s - loss: 1.3713 - acc: 0.3006\n",
            "Epoch 96/100\n",
            " - 0s - loss: 1.3720 - acc: 0.2826\n",
            "Epoch 97/100\n",
            " - 0s - loss: 1.3712 - acc: 0.2852\n",
            "Epoch 98/100\n",
            " - 0s - loss: 1.3727 - acc: 0.2981\n",
            "Epoch 99/100\n",
            " - 0s - loss: 1.3725 - acc: 0.2865\n",
            "Epoch 100/100\n",
            " - 0s - loss: 1.3730 - acc: 0.2826\n",
            "Epoch 1/100\n",
            " - 3s - loss: 1.4061 - acc: 0.2358\n",
            "Epoch 2/100\n",
            " - 0s - loss: 1.3877 - acc: 0.2552\n",
            "Epoch 3/100\n",
            " - 0s - loss: 1.3855 - acc: 0.2732\n",
            "Epoch 4/100\n",
            " - 0s - loss: 1.3831 - acc: 0.2771\n",
            "Epoch 5/100\n",
            " - 0s - loss: 1.3828 - acc: 0.2771\n",
            "Epoch 6/100\n",
            " - 0s - loss: 1.3817 - acc: 0.2835\n",
            "Epoch 7/100\n",
            " - 0s - loss: 1.3808 - acc: 0.2835\n",
            "Epoch 8/100\n",
            " - 0s - loss: 1.3805 - acc: 0.2784\n",
            "Epoch 9/100\n",
            " - 0s - loss: 1.3812 - acc: 0.2861\n",
            "Epoch 10/100\n",
            " - 0s - loss: 1.3816 - acc: 0.2899\n",
            "Epoch 11/100\n",
            " - 0s - loss: 1.3797 - acc: 0.2848\n",
            "Epoch 12/100\n",
            " - 0s - loss: 1.3799 - acc: 0.2809\n",
            "Epoch 13/100\n",
            " - 0s - loss: 1.3801 - acc: 0.2990\n",
            "Epoch 14/100\n",
            " - 0s - loss: 1.3789 - acc: 0.2887\n",
            "Epoch 15/100\n",
            " - 0s - loss: 1.3784 - acc: 0.2912\n",
            "Epoch 16/100\n",
            " - 0s - loss: 1.3788 - acc: 0.2771\n",
            "Epoch 17/100\n",
            " - 0s - loss: 1.3777 - acc: 0.3106\n",
            "Epoch 18/100\n",
            " - 0s - loss: 1.3786 - acc: 0.2925\n",
            "Epoch 19/100\n",
            " - 0s - loss: 1.3777 - acc: 0.3067\n",
            "Epoch 20/100\n",
            " - 0s - loss: 1.3780 - acc: 0.2925\n",
            "Epoch 21/100\n",
            " - 0s - loss: 1.3770 - acc: 0.2977\n",
            "Epoch 22/100\n",
            " - 0s - loss: 1.3777 - acc: 0.2938\n",
            "Epoch 23/100\n",
            " - 0s - loss: 1.3764 - acc: 0.3015\n",
            "Epoch 24/100\n",
            " - 0s - loss: 1.3766 - acc: 0.3183\n",
            "Epoch 25/100\n",
            " - 0s - loss: 1.3769 - acc: 0.3093\n",
            "Epoch 26/100\n",
            " - 0s - loss: 1.3761 - acc: 0.3041\n",
            "Epoch 27/100\n",
            " - 0s - loss: 1.3756 - acc: 0.2990\n",
            "Epoch 28/100\n",
            " - 0s - loss: 1.3771 - acc: 0.3028\n",
            "Epoch 29/100\n",
            " - 0s - loss: 1.3752 - acc: 0.3041\n",
            "Epoch 30/100\n",
            " - 0s - loss: 1.3754 - acc: 0.3028\n",
            "Epoch 31/100\n",
            " - 0s - loss: 1.3756 - acc: 0.3054\n",
            "Epoch 32/100\n",
            " - 0s - loss: 1.3749 - acc: 0.2977\n",
            "Epoch 33/100\n",
            " - 0s - loss: 1.3744 - acc: 0.3003\n",
            "Epoch 34/100\n",
            " - 0s - loss: 1.3748 - acc: 0.2990\n",
            "Epoch 35/100\n",
            " - 0s - loss: 1.3735 - acc: 0.3054\n",
            "Epoch 36/100\n",
            " - 0s - loss: 1.3739 - acc: 0.2899\n",
            "Epoch 37/100\n",
            " - 0s - loss: 1.3732 - acc: 0.2925\n",
            "Epoch 38/100\n",
            " - 0s - loss: 1.3730 - acc: 0.2990\n",
            "Epoch 39/100\n",
            " - 0s - loss: 1.3727 - acc: 0.2977\n",
            "Epoch 40/100\n",
            " - 0s - loss: 1.3726 - acc: 0.2938\n",
            "Epoch 41/100\n",
            " - 0s - loss: 1.3729 - acc: 0.2912\n",
            "Epoch 42/100\n",
            " - 0s - loss: 1.3719 - acc: 0.2899\n",
            "Epoch 43/100\n",
            " - 0s - loss: 1.3729 - acc: 0.2964\n",
            "Epoch 44/100\n",
            " - 0s - loss: 1.3720 - acc: 0.2887\n",
            "Epoch 45/100\n",
            " - 0s - loss: 1.3724 - acc: 0.2887\n",
            "Epoch 46/100\n",
            " - 0s - loss: 1.3712 - acc: 0.2899\n",
            "Epoch 47/100\n",
            " - 0s - loss: 1.3706 - acc: 0.2951\n",
            "Epoch 48/100\n",
            " - 0s - loss: 1.3706 - acc: 0.2899\n",
            "Epoch 49/100\n",
            " - 0s - loss: 1.3713 - acc: 0.2990\n",
            "Epoch 50/100\n",
            " - 0s - loss: 1.3708 - acc: 0.2951\n",
            "Epoch 51/100\n",
            " - 0s - loss: 1.3704 - acc: 0.2899\n",
            "Epoch 52/100\n",
            " - 0s - loss: 1.3703 - acc: 0.2951\n",
            "Epoch 53/100\n",
            " - 0s - loss: 1.3700 - acc: 0.2912\n",
            "Epoch 54/100\n",
            " - 0s - loss: 1.3698 - acc: 0.2887\n",
            "Epoch 55/100\n",
            " - 0s - loss: 1.3685 - acc: 0.2990\n",
            "Epoch 56/100\n",
            " - 0s - loss: 1.3699 - acc: 0.3003\n",
            "Epoch 57/100\n",
            " - 0s - loss: 1.3692 - acc: 0.2938\n",
            "Epoch 58/100\n",
            " - 0s - loss: 1.3688 - acc: 0.2912\n",
            "Epoch 59/100\n",
            " - 0s - loss: 1.3685 - acc: 0.2887\n",
            "Epoch 60/100\n",
            " - 0s - loss: 1.3679 - acc: 0.2990\n",
            "Epoch 61/100\n",
            " - 0s - loss: 1.3687 - acc: 0.2912\n",
            "Epoch 62/100\n",
            " - 0s - loss: 1.3675 - acc: 0.2990\n",
            "Epoch 63/100\n",
            " - 0s - loss: 1.3679 - acc: 0.2938\n",
            "Epoch 64/100\n",
            " - 0s - loss: 1.3678 - acc: 0.3015\n",
            "Epoch 65/100\n",
            " - 0s - loss: 1.3680 - acc: 0.2977\n",
            "Epoch 66/100\n",
            " - 0s - loss: 1.3674 - acc: 0.2912\n",
            "Epoch 67/100\n",
            " - 0s - loss: 1.3671 - acc: 0.2951\n",
            "Epoch 68/100\n",
            " - 0s - loss: 1.3677 - acc: 0.3003\n",
            "Epoch 69/100\n",
            " - 0s - loss: 1.3660 - acc: 0.3041\n",
            "Epoch 70/100\n",
            " - 0s - loss: 1.3668 - acc: 0.2938\n",
            "Epoch 71/100\n",
            " - 0s - loss: 1.3656 - acc: 0.2938\n",
            "Epoch 72/100\n",
            " - 0s - loss: 1.3671 - acc: 0.2990\n",
            "Epoch 73/100\n",
            " - 0s - loss: 1.3666 - acc: 0.2925\n",
            "Epoch 74/100\n",
            " - 0s - loss: 1.3659 - acc: 0.2977\n",
            "Epoch 75/100\n",
            " - 0s - loss: 1.3664 - acc: 0.2964\n",
            "Epoch 76/100\n",
            " - 0s - loss: 1.3665 - acc: 0.2848\n",
            "Epoch 77/100\n",
            " - 0s - loss: 1.3673 - acc: 0.3093\n",
            "Epoch 78/100\n",
            " - 0s - loss: 1.3654 - acc: 0.2964\n",
            "Epoch 79/100\n",
            " - 0s - loss: 1.3658 - acc: 0.3067\n",
            "Epoch 80/100\n",
            " - 0s - loss: 1.3647 - acc: 0.2938\n",
            "Epoch 81/100\n",
            " - 0s - loss: 1.3650 - acc: 0.2912\n",
            "Epoch 82/100\n",
            " - 0s - loss: 1.3654 - acc: 0.3054\n",
            "Epoch 83/100\n",
            " - 0s - loss: 1.3650 - acc: 0.2938\n",
            "Epoch 84/100\n",
            " - 0s - loss: 1.3644 - acc: 0.2912\n",
            "Epoch 85/100\n",
            " - 0s - loss: 1.3640 - acc: 0.3003\n",
            "Epoch 86/100\n",
            " - 0s - loss: 1.3640 - acc: 0.2977\n",
            "Epoch 87/100\n",
            " - 0s - loss: 1.3652 - acc: 0.3015\n",
            "Epoch 88/100\n",
            " - 0s - loss: 1.3650 - acc: 0.2912\n",
            "Epoch 89/100\n",
            " - 0s - loss: 1.3646 - acc: 0.2977\n",
            "Epoch 90/100\n",
            " - 0s - loss: 1.3644 - acc: 0.3041\n",
            "Epoch 91/100\n",
            " - 0s - loss: 1.3632 - acc: 0.2964\n",
            "Epoch 92/100\n",
            " - 0s - loss: 1.3637 - acc: 0.2874\n",
            "Epoch 93/100\n",
            " - 0s - loss: 1.3644 - acc: 0.3119\n",
            "Epoch 94/100\n",
            " - 0s - loss: 1.3639 - acc: 0.2977\n",
            "Epoch 95/100\n",
            " - 0s - loss: 1.3635 - acc: 0.3041\n",
            "Epoch 96/100\n",
            " - 0s - loss: 1.3639 - acc: 0.3003\n",
            "Epoch 97/100\n",
            " - 0s - loss: 1.3643 - acc: 0.3093\n",
            "Epoch 98/100\n",
            " - 0s - loss: 1.3646 - acc: 0.3015\n",
            "Epoch 99/100\n",
            " - 0s - loss: 1.3642 - acc: 0.2925\n",
            "Epoch 100/100\n",
            " - 0s - loss: 1.3627 - acc: 0.3003\n",
            "Model Performance: mean: 26.42% std: (1.10%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HejJz7FafNrI",
        "outputId": "d8d4efe6-3d04-45c4-8536-eb86e3fdcd00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYAJox_1fnUX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvI8qGCcdhIl",
        "outputId": "4d28a2cf-37ea-4bea-8070-806ca4911e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "#set early stopping monitor so the model stops training when it won't improve anymore\n",
        "early_stopping_monitor = EarlyStopping(patience=3)\n",
        "\n",
        "model = model()\n",
        "#train model\n",
        "model.fit(X, y, epochs=30, validation_split=0.2, callbacks=[early_stopping_monitor])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1108 samples, validate on 277 samples\n",
            "Epoch 1/30\n",
            "1108/1108 [==============================] - 4s 4ms/step - loss: 1.4232 - acc: 0.2410 - val_loss: 1.3830 - val_acc: 0.3285\n",
            "Epoch 2/30\n",
            "1108/1108 [==============================] - 0s 78us/step - loss: 1.3878 - acc: 0.2446 - val_loss: 1.3788 - val_acc: 0.2924\n",
            "Epoch 3/30\n",
            "1108/1108 [==============================] - 0s 70us/step - loss: 1.3870 - acc: 0.2545 - val_loss: 1.3802 - val_acc: 0.3141\n",
            "Epoch 4/30\n",
            "1108/1108 [==============================] - 0s 70us/step - loss: 1.3883 - acc: 0.2383 - val_loss: 1.3792 - val_acc: 0.3032\n",
            "Epoch 5/30\n",
            "1108/1108 [==============================] - 0s 72us/step - loss: 1.3862 - acc: 0.2473 - val_loss: 1.3814 - val_acc: 0.2780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f670373aef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    }
  ]
}